{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Python version: 3.9.6 (default, Oct 17 2025, 17:15:53) \n",
      "[Clang 17.0.0 (clang-1700.4.4.1)]\n",
      "Current working directory: /Users/kgcz094/Documents/MTECH/Assignment 2/ML/Heart_Disease_Prediction/model\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DOWNLOADING HEART DISEASE DATASET FROM KAGGLE\n",
      "======================================================================\n",
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (1.0.0).\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/johnsmith88/heart-disease-dataset?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.18k/6.18k [00:00<00:00, 4.81MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "\n",
      " Dataset downloaded successfully!\n",
      "ðŸ“ Download location: /Users/kgcz094/.cache/kagglehub/datasets/johnsmith88/heart-disease-dataset/versions/2\n",
      "\n",
      " Files in download directory:\n",
      "   - heart.csv (37.22 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"DOWNLOADING HEART DISEASE DATASET FROM KAGGLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Download latest version of the dataset\n",
    "    download_path = kagglehub.dataset_download(\"johnsmith88/heart-disease-dataset\")\n",
    "    \n",
    "    print(f\"\\n Dataset downloaded successfully!\")\n",
    "    print(f\"ðŸ“ Download location: {download_path}\")\n",
    "    \n",
    "    # List files in downloaded directory\n",
    "    print(f\"\\n Files in download directory:\")\n",
    "    for file in os.listdir(download_path):\n",
    "        file_path = os.path.join(download_path, file)\n",
    "        file_size = os.path.getsize(file_path) / 1024  # Convert to KB\n",
    "        print(f\"   - {file} ({file_size:.2f} KB)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n Error downloading dataset: {e}\")\n",
    "    print(\"\\n  Troubleshooting steps:\")\n",
    "    print(\"1. Ensure you have a Kaggle account\")\n",
    "    print(\"2. Download kaggle.json from Kaggle.com â†’ Settings â†’ API\")\n",
    "    print(\"3. Place it at: ~/.kaggle/kaggle.json\")\n",
    "    print(\"4. Set permissions: chmod 600 ~/.kaggle/kaggle.json\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COPYING DATASET TO PROJECT DATA FOLDER\n",
      "======================================================================\n",
      "\n",
      " Dataset copied successfully!\n",
      " Destination: ../data/heart.csv\n",
      " File verified!\n",
      " File size: 37.22 KB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COPYING DATASET TO PROJECT DATA FOLDER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "data_dir = Path('../data')\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Source and destination paths\n",
    "source_file = os.path.join(download_path, 'heart.csv')\n",
    "destination_file = data_dir / 'heart.csv'\n",
    "\n",
    "# Copy file\n",
    "shutil.copy(source_file, destination_file)\n",
    "\n",
    "print(f\"\\n Dataset copied successfully!\")\n",
    "print(f\" Destination: {destination_file}\")\n",
    "\n",
    "# Verify file exists\n",
    "if destination_file.exists():\n",
    "    file_size = destination_file.stat().st_size / 1024  # KB\n",
    "    print(f\" File verified!\")\n",
    "    print(f\" File size: {file_size:.2f} KB\")\n",
    "else:\n",
    "    print(\" Error: File not found at destination!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LOADING AND PREVIEWING DATASET\n",
      "======================================================================\n",
      "\n",
      " Dataset Shape: (1025, 14)\n",
      "   - Rows (instances): 1025\n",
      "   - Columns (features + target): 14\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LOADING AND PREVIEWING DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(destination_file)\n",
    "\n",
    "print(f\"\\n Dataset Shape: {df.shape}\")\n",
    "print(f\"   - Rows (instances): {df.shape[0]}\")\n",
    "print(f\"   - Columns (features + target): {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATASET COLUMNS\n",
      "======================================================================\n",
      " 1. age             | Type: int64    | Unique values: 41\n",
      " 2. sex             | Type: int64    | Unique values: 2\n",
      " 3. cp              | Type: int64    | Unique values: 4\n",
      " 4. trestbps        | Type: int64    | Unique values: 49\n",
      " 5. chol            | Type: int64    | Unique values: 152\n",
      " 6. fbs             | Type: int64    | Unique values: 2\n",
      " 7. restecg         | Type: int64    | Unique values: 3\n",
      " 8. thalach         | Type: int64    | Unique values: 91\n",
      " 9. exang           | Type: int64    | Unique values: 2\n",
      "10. oldpeak         | Type: float64  | Unique values: 40\n",
      "11. slope           | Type: int64    | Unique values: 3\n",
      "12. ca              | Type: int64    | Unique values: 5\n",
      "13. thal            | Type: int64    | Unique values: 4\n",
      "14. target          | Type: int64    | Unique values: 2\n",
      "\n",
      "======================================================================\n",
      "FIRST 5 ROWS\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET COLUMNS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    dtype = df[col].dtype\n",
    "    unique_vals = df[col].nunique()\n",
    "    print(f\"{i:2d}. {col:15s} | Type: {str(dtype):8s} | Unique values: {unique_vals}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FIRST 5 ROWS\")\n",
    "print(\"=\"*70)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATA QUALITY CHECK\n",
      "======================================================================\n",
      "\n",
      " Missing Values:\n",
      "No missing values found!\n",
      "\n",
      " Duplicate Rows: 723\n",
      "\n",
      " Data Types:\n",
      "int64      13\n",
      "float64     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Missing values\n",
    "missing = df.isnull().sum()\n",
    "print(\"\\n Missing Values:\")\n",
    "if missing.sum() == 0:\n",
    "    print(\"No missing values found!\")\n",
    "else:\n",
    "    print(missing[missing > 0])\n",
    "\n",
    "# Duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\n Duplicate Rows: {duplicates}\")\n",
    "if duplicates == 0:\n",
    "    print(\" No duplicate rows found!\")\n",
    "\n",
    "# Data types\n",
    "print(\"\\n Data Types:\")\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ASSIGNMENT REQUIREMENTS CHECK\n",
      "======================================================================\n",
      "\n",
      "âœ“ Minimum Feature Size: 12\n",
      "  Current: 13 features\n",
      " PASS\n",
      "\n",
      "âœ“ Minimum Instance Size: 500\n",
      "  Current: 1025 instances\n",
      "  PASS\n",
      "\n",
      "âœ“ Target Variable: 'target'\n",
      "  Found\n",
      "\n",
      "  Target distribution:\n",
      "        Count\n",
      "target       \n",
      "1         526\n",
      "0         499\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ASSIGNMENT REQUIREMENTS CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Requirement 1: Minimum 12 features\n",
    "num_features = df.shape[1] - 1  # Exclude target\n",
    "print(f\"\\nâœ“ Minimum Feature Size: 12\")\n",
    "print(f\"  Current: {num_features} features\")\n",
    "if num_features >= 12:\n",
    "    print(\" PASS\")\n",
    "else:\n",
    "    print(f\" FAIL - Need at least {12 - num_features} more features\")\n",
    "\n",
    "# Requirement 2: Minimum 500 instances\n",
    "num_instances = df.shape[0]\n",
    "print(f\"\\nâœ“ Minimum Instance Size: 500\")\n",
    "print(f\"  Current: {num_instances} instances\")\n",
    "if num_instances >= 500:\n",
    "    print(\"  PASS\")\n",
    "else:\n",
    "    print(f\" FAIL - Need at least {500 - num_instances} more instances\")\n",
    "\n",
    "# Target variable\n",
    "print(f\"\\nâœ“ Target Variable: 'target'\")\n",
    "if 'target' in df.columns:\n",
    "    print(\"  Found\")\n",
    "    print(f\"\\n  Target distribution:\")\n",
    "    print(df['target'].value_counts().to_frame('Count'))\n",
    "else:\n",
    "    print(\"  Not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SAVING DATASET SUMMARY\n",
      "======================================================================\n",
      "Dataset             : Heart Disease Dataset\n",
      "Source              : Kaggle (johnsmith88/heart-disease-dataset)\n",
      "File                : heart.csv\n",
      "Rows                : 1025\n",
      "Columns             : 14\n",
      "Features            : 13\n",
      "Target              : target (binary classification)\n",
      "Missing Values      : 0\n",
      "Duplicates          : 723\n",
      "File Size (KB)      : 37.22\n",
      "\n",
      " Summary saved to: ../data/dataset_summary.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING DATASET SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create summary dictionary\n",
    "summary = {\n",
    "    'Dataset': 'Heart Disease Dataset',\n",
    "    'Source': 'Kaggle (johnsmith88/heart-disease-dataset)',\n",
    "    'File': 'heart.csv',\n",
    "    'Rows': df.shape[0],\n",
    "    'Columns': df.shape[1],\n",
    "    'Features': df.shape[1] - 1,\n",
    "    'Target': 'target (binary classification)',\n",
    "    'Missing Values': df.isnull().sum().sum(),\n",
    "    'Duplicates': df.duplicated().sum(),\n",
    "    'File Size (KB)': f\"{destination_file.stat().st_size / 1024:.2f}\"\n",
    "}\n",
    "\n",
    "# Print summary\n",
    "for key, value in summary.items():\n",
    "    print(f\"{key:20s}: {value}\")\n",
    "\n",
    "# Save to text file\n",
    "summary_file = data_dir / 'dataset_summary.txt'\n",
    "with open(summary_file, 'w') as f:\n",
    "    f.write(\"HEART DISEASE DATASET SUMMARY\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    for key, value in summary.items():\n",
    "        f.write(f\"{key:20s}: {value}\\n\")\n",
    "\n",
    "print(f\"\\n Summary saved to: {summary_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATASET DOWNLOAD COMPLETE \n",
      "======================================================================\n",
      "\n",
      " Files created:\n",
      "   1. ../data/heart.csv\n",
      "   2. ../data/dataset_summary.txt\n",
      "\n",
      " Next Steps:\n",
      "   1. Run '01_data_exploration.ipynb' to explore the data\n",
      "   2. Run '02_train_models.ipynb' to train ML models\n",
      "\n",
      " Dataset is ready for analysis!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATASET DOWNLOAD COMPLETE \")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n Files created:\")\n",
    "print(f\"   1. {destination_file}\")\n",
    "print(f\"   2. {summary_file}\")\n",
    "\n",
    "print(\"\\n Next Steps:\")\n",
    "print(\"   1. Run '01_data_exploration.ipynb' to explore the data\")\n",
    "print(\"   2. Run '02_train_models.ipynb' to train ML models\")\n",
    "\n",
    "print(\"\\n Dataset is ready for analysis!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
